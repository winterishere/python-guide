#
msgid ""
msgstr ""
"Project-Id-Version: pythonguide 0.0.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-10-11 08:03+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.3.4\n"

#: ../../scenarios/speed.rst:2
msgid "Speed"
msgstr ""

#: ../../scenarios/speed.rst:4
msgid ""
"CPython, the most commonly used implementation of Python, is slow for CPU"
" bound tasks. `PyPy`_ is fast."
msgstr ""

#: ../../scenarios/speed.rst:7
msgid ""
"Using a slightly modified version of `David Beazley's`_ CPU bound test "
"code (added loop for multiple tests), you can see the difference between "
"CPython and PyPy's processing."
msgstr ""

#: ../../scenarios/speed.rst:37
msgid "Context"
msgstr ""

#: ../../scenarios/speed.rst:41 ../../scenarios/speed.rst:59
msgid "The GIL"
msgstr ""

#: ../../scenarios/speed.rst:43
msgid ""
"`The GIL`_ (Global Interpreter Lock) is how Python allows multiple "
"threads to operate at the same time. Python's memory management isn't "
"entirely thread-safe, so the GIL is required to prevent multiple threads "
"from running the same Python code at once."
msgstr ""

#: ../../scenarios/speed.rst:48
msgid ""
"David Beazley has a great `guide`_ on how the GIL operates. He also "
"covers the `new GIL`_ in Python 3.2. His results show that maximizing "
"performance in a Python application requires a strong understanding of "
"the GIL, how it affects your specific application, how many cores you "
"have, and where your application bottlenecks are."
msgstr ""

#: ../../scenarios/speed.rst:55 ../../scenarios/speed.rst:65
msgid "C Extensions"
msgstr ""

#: ../../scenarios/speed.rst:61
msgid ""
"`Special care`_ must be taken when writing C extensions to make sure you "
"register your threads with the interpreter."
msgstr ""

#: ../../scenarios/speed.rst:69
msgid "Cython"
msgstr ""

#: ../../scenarios/speed.rst:71
msgid ""
"`Cython <http://cython.org/>`_ implements a superset of the Python "
"language with which you are able to write C and C++ modules for Python. "
"Cython also allows you to call functions from compiled C libraries. Using"
" Cython allows you to take advantage of Python's strong typing of "
"variables and operations."
msgstr ""

#: ../../scenarios/speed.rst:76
msgid "Here's an example of strong typing with Cython:"
msgstr ""

#: ../../scenarios/speed.rst:103
msgid ""
"This implementation of an algorithm to find prime numbers has some "
"additional keywords compared to the next one, which is implemented in "
"pure Python:"
msgstr ""

#: ../../scenarios/speed.rst:128
msgid ""
"Notice that in the Cython version you declare integers and integer arrays"
" to be compiled into C types while also creating a Python list:"
msgstr ""

#: ../../scenarios/speed.rst:151
msgid ""
"What is the difference? In the upper Cython version you can see the "
"declaration of the variable types and the integer array in a similar way "
"as in standard C. For example `cdef int n,k,i` in line 3. This additional"
" type declaration (i.e. integer) allows the Cython compiler to generate "
"more efficient C code from the second version. While standard Python code"
" is saved in :file:`*.py` files, Cython code is saved in :file:`*.pyx` "
"files."
msgstr ""

#: ../../scenarios/speed.rst:158
msgid "What's the difference in speed? Let's try it!"
msgstr ""

#: ../../scenarios/speed.rst:184
msgid "These lines both need a remark:"
msgstr ""

#: ../../scenarios/speed.rst:192
msgid ""
"The `pyximport` module allows you to import :file:`*.pyx` files (e.g., "
":file:`primesCy.pyx`) with the Cython-compiled version of the `primes` "
"function. The `pyximport.install()` command allows the Python interpreter"
" to start the Cython compiler directly to generate C-code, which is "
"automatically compiled to a :file:`*.so` C-library. Cython is then able "
"to import this library for you in your Python code, easily and "
"efficiently. With the `time.time()` function you are able to compare the "
"time between these 2 different calls to find 500 prime numbers. On a "
"standard notebook (dual core AMD E-450 1.6 GHz), the measured values are:"
msgstr ""

#: ../../scenarios/speed.rst:209
msgid ""
"And here the output of an embedded `ARM beaglebone "
"<http://beagleboard.org/Products/BeagleBone>`_ machine:"
msgstr ""

#: ../../scenarios/speed.rst:219
msgid "Pyrex"
msgstr ""

#: ../../scenarios/speed.rst:223
msgid "Shedskin?"
msgstr ""

#: ../../scenarios/speed.rst:226
msgid "Numba"
msgstr ""

#: ../../scenarios/speed.rst
msgid "Todo"
msgstr ""

#: ../../scenarios/speed.rst:227
msgid "Write about Numba and the autojit compiler for NumPy"
msgstr ""

#: ../../scenarios/speed.rst:230
msgid "Concurrency"
msgstr ""

#: ../../scenarios/speed.rst:234
msgid "Concurrent.futures"
msgstr ""

#: ../../scenarios/speed.rst:236
msgid ""
"The `concurrent.futures`_ module is a module in the standard library that"
" provides a \"high-level interface for asynchronously executing "
"callables\". It abstracts away a lot of the more complicated details "
"about using multiple threads or processes for concurrency, and allows the"
" user to focus on accomplishing the task at hand."
msgstr ""

#: ../../scenarios/speed.rst:242
msgid ""
"The `concurrent.futures`_ module exposes two main classes, the "
"`ThreadPoolExecutor` and the `ProcessPoolExecutor`. The "
"ThreadPoolExecutor will create a pool of worker threads that a user can "
"submit jobs to. These jobs will then be executed in another thread when "
"the next worker thread becomes available."
msgstr ""

#: ../../scenarios/speed.rst:248
msgid ""
"The ProcessPoolExecutor works in the same way, except instead of using "
"multiple threads for its workers, it will use multiple processes. This "
"makes it possible to side-step the GIL, however because of the way things"
" are passed to worker processes, only picklable objects can be executed "
"and returned."
msgstr ""

#: ../../scenarios/speed.rst:253
msgid ""
"Because of the way the GIL works, a good rule of thumb is to use a "
"ThreadPoolExecutor when the task being executed involves a lot of "
"blocking (i.e. making requests over the network) and to use a "
"ProcessPoolExecutor executor when the task is computationally expensive."
msgstr ""

#: ../../scenarios/speed.rst:258
msgid ""
"There are two main ways of executing things in parallel using the two "
"Executors. One way is with the `map(func, iterables)` method. This works "
"almost exactly like the builtin `map()` function, except it will execute "
"everything in parallel. :"
msgstr ""

#: ../../scenarios/speed.rst:280
msgid ""
"For even more control, the `submit(func, *args, **kwargs)` method will "
"schedule a callable to be executed ( as `func(*args, **kwargs)`) and "
"returns a `Future`_ object that represents the execution of the callable."
msgstr ""

#: ../../scenarios/speed.rst:284
msgid ""
"The Future object provides various methods that can be used to check on "
"the progress of the scheduled callable. These include:"
msgstr ""

#: ../../scenarios/speed.rst:287
msgid "cancel()"
msgstr ""

#: ../../scenarios/speed.rst:288
msgid "Attempt to cancel the call."
msgstr ""

#: ../../scenarios/speed.rst:289
msgid "cancelled()"
msgstr ""

#: ../../scenarios/speed.rst:290
msgid "Return True if the call was successfully cancelled."
msgstr ""

#: ../../scenarios/speed.rst:292
msgid "running()"
msgstr ""

#: ../../scenarios/speed.rst:292
msgid ""
"Return True if the call is currently being executed and cannot be "
"cancelled."
msgstr ""

#: ../../scenarios/speed.rst:294
msgid "done()"
msgstr ""

#: ../../scenarios/speed.rst:295
msgid "Return True if the call was successfully cancelled or finished running."
msgstr ""

#: ../../scenarios/speed.rst:297
msgid "result()"
msgstr ""

#: ../../scenarios/speed.rst:297
msgid ""
"Return the value returned by the call. Note that this call will block "
"until the scheduled callable returns by default."
msgstr ""

#: ../../scenarios/speed.rst:300
msgid "exception()"
msgstr ""

#: ../../scenarios/speed.rst:300
msgid ""
"Return the exception raised by the call. If no exception was raised then "
"this returns `None`. Note that this will block just like `result()`."
msgstr ""

#: ../../scenarios/speed.rst:305
msgid "add_done_callback(fn)"
msgstr ""

#: ../../scenarios/speed.rst:303
msgid ""
"Attach a callback function that will be executed (as `fn(future)`) when "
"the scheduled callable returns."
msgstr ""

#: ../../scenarios/speed.rst:344
msgid ""
"The `concurrent.futures`_ module contains two helper functions for "
"working with Futures. The `as_completed(futures)` function returns an "
"iterator over the list of futures, yielding the futures as they complete."
msgstr ""

#: ../../scenarios/speed.rst:348
msgid ""
"The `wait(futures)` function will simply block until all futures in the "
"list of futures provided have completed."
msgstr ""

#: ../../scenarios/speed.rst:351
msgid ""
"For more information, on using the `concurrent.futures`_ module, consult "
"the official documentation."
msgstr ""

#: ../../scenarios/speed.rst:355
msgid "Threading"
msgstr ""

#: ../../scenarios/speed.rst:357
msgid ""
"The standard library comes with a `threading`_ module that allows a user "
"to work with multiple threads manually."
msgstr ""

#: ../../scenarios/speed.rst:360
msgid ""
"Running a function in another thread is as simple as passing a callable "
"and it's arguments to `Thread`'s constructor and then calling `start()`:"
msgstr ""

#: ../../scenarios/speed.rst:375
msgid "To wait until the thread has terminated, call `join()`:"
msgstr ""

#: ../../scenarios/speed.rst:381
msgid ""
"After calling `join()`, it is always a good idea to check whether the "
"thread is still alive (because the join call timed out):"
msgstr ""

#: ../../scenarios/speed.rst:391
msgid ""
"Because multiple threads have access to the same section of memory, "
"sometimes there might be situations where two or more threads are trying "
"to write to the same resource at the same time or where the output is "
"dependent on the sequence or timing of certain events. This is called a "
"`data race`_ or race condition. When this happens, the output will be "
"garbled or you may encounter problems which are difficult to debug. A "
"good example is this `stackoverflow post`_."
msgstr ""

#: ../../scenarios/speed.rst:398
msgid ""
"The way this can be avoided is by using a `Lock`_ that each thread needs "
"to acquire before writing to a shared resource. Locks can be acquired and"
" released through either the contextmanager protocol (`with` statement), "
"or by using `acquire()` and `release()` directly. Here is a (rather "
"contrived) example:"
msgstr ""

#: ../../scenarios/speed.rst:430
msgid ""
"Here, we have a bunch of threads checking for changes on a list of sites "
"and whenever there are any changes, they attempt to write those changes "
"to a file by calling `log(changes)`. When `log()` is called, it will wait"
" to acquire the lock with `with file_lock:`. This ensures that at any one"
" time, only one thread is writing to the file."
msgstr ""

#: ../../scenarios/speed.rst:437
msgid "Spawning Processes"
msgstr ""

#: ../../scenarios/speed.rst:441
msgid "Multiprocessing"
msgstr ""

#~ msgid ""
#~ "Using a slightly modified version of "
#~ "`David Beazleys`_ CPU bound test code"
#~ " (added loop for multiple tests), you"
#~ " can see the difference between "
#~ "CPython and PyPy's processing."
#~ msgstr ""

